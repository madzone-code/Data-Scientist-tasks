{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4d8f6e",
   "metadata": {},
   "source": [
    "# Первая задача."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c4cd4a",
   "metadata": {},
   "source": [
    "2 способа распознавания:\n",
    "- *нейросеть whisper от OpenAI (требует установленного ffmpeg)*\n",
    "- *speech_recognition от google. ffmpeg не нужен.*\n",
    "\n",
    "Звуковой файл подготавливаем 2 способами:\n",
    "- *удаляем шум, нормализуем громкость*\n",
    "- *удаляем шум, выделяем голос, нормализуем громкость (метод тяжелый)*\n",
    "\n",
    "На выходе получаем 6 вариантов распознанного текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек\n",
    "%pip install moviepy librosa noisereduce soundfile SpeechRecognition openai-whisper demucs\n",
    "\n",
    "# Установка ffmpeg (для Windows/Linux/Mac) для whisper.\n",
    "try:\n",
    "    import subprocess\n",
    "    subprocess.run([\"ffmpeg\", \"-version\"], check=True, capture_output=True)\n",
    "    print(\"ffmpeg уже установлен\")\n",
    "except:\n",
    "    print(\"Установка ffmpeg...\")\n",
    "    import platform\n",
    "    if platform.system() == \"Windows\":\n",
    "        print(\"Для Windows установите ffmpeg вручную: https://ffmpeg.org/download.html\")\n",
    "    elif platform.system() == \"Linux\":\n",
    "        !apt-get update && apt-get install -y ffmpeg\n",
    "    elif platform.system() == \"Darwin\":  # MacOS\n",
    "        !brew install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb19322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указываем путь к аудиофайлу\n",
    "audio_path = \"task1/data/download_14.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0783483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import AudioFileClip\n",
    "import os\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "import speech_recognition as sr\n",
    "import subprocess\n",
    "import whisper\n",
    "\n",
    "\n",
    "def convertation(audio_path):\n",
    "    \"\"\"Конвертирование звукового файла в wav.\"\"\"\n",
    "\n",
    "    # Если уже wav, то не конвертируем.\n",
    "    if audio_path.lower().endswith('.wav'):\n",
    "        return audio_path\n",
    "\n",
    "    # Сохраняем файл по тому же адресу, но другим расширением.\n",
    "    wav_path = os.path.splitext(audio_path)[0] + '.wav'\n",
    "\n",
    "    audio = AudioFileClip(audio_path)\n",
    "    audio.write_audiofile(wav_path, codec='pcm_s16le')\n",
    "    audio.close()\n",
    "\n",
    "    print('Файл успешно конвертирован.')\n",
    "    return wav_path\n",
    "\n",
    "\n",
    "def enhance_audio(audio_path):\n",
    "    \"\"\"Базовая функция улучшения аудио. Убирает шумы, нормализует громкость.\"\"\"\n",
    "\n",
    "    # Загрузка аудио\n",
    "    audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
    "    # Удаление шума\n",
    "    reduced_noise = nr.reduce_noise(y=audio_data, sr=sample_rate)\n",
    "    # Нормализация громкости\n",
    "    normalized_audio = librosa.util.normalize(reduced_noise)\n",
    "    # Сохранение обработанного аудио\n",
    "    enhance_path = os.path.splitext(audio_path)[0] + '_enhance.wav'\n",
    "    sf.write(enhance_path, normalized_audio, sample_rate)\n",
    "\n",
    "    return enhance_path\n",
    "\n",
    "\n",
    "def advance_enhance_audio(wav_path):\n",
    "    \"\"\"\n",
    "    Продвинутая функция улучшения аудио.\n",
    "    Убирает шумы, оставляет один голос, нормализует громкость.\n",
    "\n",
    "    \"\"\"\n",
    "    # Выходной файл\n",
    "    advance_enhanced_path = (\n",
    "        os.path.splitext(wav_path)[0] + '_advance_enhance.wav')\n",
    "    # Загрузка аудио\n",
    "    audio, sample_rate = librosa.load(wav_path, sr=16000)  # 16 кГц для Whisper\n",
    "    # Легкое подавление шума\n",
    "    reduced_noise = nr.reduce_noise(y=audio, sr=sample_rate, stationary=False,\n",
    "                                    prop_decrease=0.75)\n",
    "    # Сохранение временного файла\n",
    "    temp_file = \"temp.wav\"\n",
    "    sf.write(temp_file, reduced_noise, sample_rate)\n",
    "    # Выделение голоса с Demucs.\n",
    "    subprocess.run([\"demucs\", \"--two-stems=vocals\", temp_file], check=True)\n",
    "    vocal_file = \"separated/htdemucs/temp/vocals.wav\"\n",
    "    # Нормализация громкости с ffmpeg\n",
    "    subprocess.run([\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", vocal_file,\n",
    "        \"-af\", \"volume=5dB\",\n",
    "        \"-ar\", \"16000\",\n",
    "        \"-y\", advance_enhanced_path\n",
    "    ], check=True)\n",
    "\n",
    "    # Удаление временных файлов\n",
    "    os.remove(temp_file)\n",
    "    if os.path.exists(\"separated\"):\n",
    "        shutil.rmtree(\"separated\")\n",
    "\n",
    "    return advance_enhanced_path\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Локальное распознавание. Не требует ffmpeg.\"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    print('Подождите, идет распознавание файла.')\n",
    "\n",
    "    try:\n",
    "        with sr.AudioFile(audio_path) as source:\n",
    "            audio = recognizer.record(source)\n",
    "            text = recognizer.recognize_google(audio, language=\"ru-RU\")\n",
    "            return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Не удалось распознать речь\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Ошибка сервиса: {e}\"\n",
    "\n",
    "\n",
    "def whisper_transcribe_audio(wav_path):\n",
    "    \"\"\"\n",
    "    Используем нейросетевую модель от OpenAI. Доступны модели tiny, base,\n",
    "    small, medium, large. Использует ffmpeg (должен быть установлен в ОС).\n",
    "    \"\"\"\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(wav_path, language=\"ru\")\n",
    "    return result[\"text\"]\n",
    "\n",
    "\n",
    "# Обработка исходного файла.\n",
    "def main():\n",
    "    # Задаем путь к обрабатываемому аудио файлу.\n",
    "    audio_path = \"task1/data/download_16.mp4\"\n",
    "\n",
    "    # Конвертируем в wav.\n",
    "    wav_path = convertation(audio_path)\n",
    "\n",
    "    # Улучшаем wav 2 способами.\n",
    "    enhanced_wav_path = enhance_audio(wav_path)\n",
    "    advance_enhanced_wav_path = advance_enhance_audio(wav_path)\n",
    "\n",
    "    # Распознаем текст\n",
    "    texts = {\n",
    "        \"original\": transcribe_audio(wav_path),\n",
    "        \"enhanced\": transcribe_audio(enhanced_wav_path),\n",
    "        \"advance_enhanced\": transcribe_audio(advance_enhanced_wav_path),\n",
    "        \"whisper\": whisper_transcribe_audio(wav_path),\n",
    "        \"whisper_enhanced\": whisper_transcribe_audio(enhanced_wav_path),\n",
    "        \"whisper_advance_enhanced\": whisper_transcribe_audio(\n",
    "            advance_enhanced_wav_path),\n",
    "    }\n",
    "\n",
    "    # Записываем все тексты в файлы по тому же адресу, что и оригинал.\n",
    "    base_path = os.path.splitext(audio_path)[0]\n",
    "    for key, text in texts.items():\n",
    "        with open(f\"{base_path}_{key}.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc524586",
   "metadata": {},
   "source": [
    "# Вторая задача."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64e41c9",
   "metadata": {},
   "source": [
    "Используем нейросеть yolo11n для сегментации автомобилей.\n",
    "Маскируем стекла и колеса.\n",
    "Вычисляем средний цвет.\n",
    "Визуализируем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек\n",
    "%pip install opencv-python numpy matplotlib ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e456a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указываем путь к фотографии автомобиля\n",
    "image_path = \"task2/data/istockphoto-494522913-612x612.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "def detect_cars(model, image_rgb):\n",
    "    \"\"\"Выполняет сегментацию автомобилей с помощью модели YOLO.\"\"\"\n",
    "    results = model(image_rgb)\n",
    "    cars = []\n",
    "    masks = []\n",
    "    for result in results:\n",
    "        for box, mask in zip(result.boxes, result.masks or []):\n",
    "            if int(box.cls) == 2:       # Класс 2 в COCO — автомобиль\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cars.append((x1, y1, x2, y2))\n",
    "                mask_data = mask.data.cpu().numpy().squeeze()\n",
    "                masks.append(mask_data)\n",
    "    return cars, masks\n",
    "\n",
    "\n",
    "def process_car(image_rgb, car_coords, mask_data):\n",
    "    \"\"\"\n",
    "    Обрабатывает один автомобиль:\n",
    "    сегментирует, исключает стёкла/колёса, вычисляет цвет.\n",
    "\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = car_coords\n",
    "    # Выделяем область автомобиля\n",
    "    car_region = image_rgb[y1:y2, x1:x2].copy()\n",
    "\n",
    "    # Изменение размера маски до размеров bounding box\n",
    "    mask_resized = cv2.resize(\n",
    "        mask_data, (x2 - x1, y2 - y1), interpolation=cv2.INTER_NEAREST)\n",
    "    mask_resized = (mask_resized > 0).astype(np.uint8) * 255\n",
    "\n",
    "    # Применение маски сегментации\n",
    "    car_segmented = cv2.bitwise_and(car_region, car_region, mask=mask_resized)\n",
    "\n",
    "    # Преобразование в HSV\n",
    "    car_hsv = cv2.cvtColor(car_segmented, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Маскирование стёкол и колёс\n",
    "    lower_glass = np.array([0, 0, 150])  # Высокая яркость\n",
    "    upper_glass = np.array([180, 50, 255])  # Низкая насыщенность\n",
    "    lower_wheels = np.array([0, 0, 0])  # Тёмные области\n",
    "    upper_wheels = np.array([180, 255, 50])  # Низкая яркость\n",
    "\n",
    "    mask_glass = cv2.inRange(car_hsv, lower_glass, upper_glass)\n",
    "    mask_wheels = cv2.inRange(car_hsv, lower_wheels, upper_wheels)\n",
    "    mask_exclude = cv2.bitwise_or(mask_glass, mask_wheels)\n",
    "    mask_body = cv2.bitwise_and(mask_resized, cv2.bitwise_not(mask_exclude))\n",
    "\n",
    "    # Применение финальной маски\n",
    "    car_body = cv2.bitwise_and(car_region, car_region, mask=mask_body)\n",
    "\n",
    "    # Вычисление среднего цвета\n",
    "    valid_pixels = car_body[mask_body > 0].reshape(-1, 3)\n",
    "    if len(valid_pixels) > 0:\n",
    "        mean_color = np.mean(valid_pixels, axis=0).astype(int)\n",
    "    else:\n",
    "        mean_color = np.array([128, 128, 128])\n",
    "\n",
    "    return tuple(mean_color)\n",
    "\n",
    "\n",
    "def visualize_results(image_rgb, cars, rgb_colors):\n",
    "    \"\"\"Визуализация.\"\"\"\n",
    "    # Копия изображения для рисования\n",
    "    vis_image = image_rgb.copy()\n",
    "\n",
    "    # Рисуем bounding box'ы и метки\n",
    "    for i, (x1, y1, x2, y2) in enumerate(cars):\n",
    "        cv2.rectangle(vis_image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        cv2.putText(vis_image, f\"Car {i+1}\", (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Исходное изображение\n",
    "    plt.subplot(1, len(cars) + 1, 1)\n",
    "    plt.imshow(vis_image)\n",
    "    plt.title(\"Автомобили с определёнными цветами\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Цветовые патчи\n",
    "    for i, color in enumerate(rgb_colors):\n",
    "        plt.subplot(1, len(cars) + 1, i + 2)\n",
    "        color_patch = np.ones((100, 100, 3)) * (np.array(color) / 255)\n",
    "        plt.imshow(color_patch)\n",
    "        plt.title(f\"Авто {i+1}\\nRGB: {color}\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Загрузка модели (vj;)\n",
    "    model = YOLO(\"yolo11n-seg.pt\")\n",
    "\n",
    "    # Подготовка изображения\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Детекция автомобилей\n",
    "    cars, masks = detect_cars(model, image_rgb)\n",
    "    if not cars:\n",
    "        print(\"Автомобили не найдены\")\n",
    "        return\n",
    "\n",
    "    # Обработка автомобилей\n",
    "    rgb_colors = []\n",
    "    for i, (car_coords, mask_data) in enumerate(zip(cars, masks)):\n",
    "        color = process_car(image_rgb, car_coords, mask_data)\n",
    "        rgb_colors.append(color)\n",
    "        print(f\"Авто {i+1}: RGB = {color}\")\n",
    "\n",
    "    # Визуализация результатов\n",
    "    visualize_results(image_rgb, cars, rgb_colors)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a05fc5",
   "metadata": {},
   "source": [
    "# Третья задача"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e4299",
   "metadata": {},
   "source": [
    "Для решения напрашивается нейронная сеть на базе сверточной основы с обучением на сгенерированных фейковых документах с аугментацией и k-fold валидацией. Проблем с реализацией не будет, но займет существенное время. Если необходимо убедиться, что я могу это сделать, посмотрите проект https://github.com/madzone-code/FaceGenderBot\n",
    "На мой взгляд, оптимальное решение в рамках тестового задания – на основе распознавания текста (писал для своего проекта). Да, оно не работает, если изображение очень низкого качества (часть предложенных паспортов). Однако, тут возникает вопрос: «а зачем такое изображение вообще классифицировать, если оно абсолютно бесполезно для дальнейшей обработки?». \n",
    "Плюс tesseract должен быть установлен в системе (прописан в PATH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fc1a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Установка необходимых библиотек\n",
    "%pip install opencv-python pytesseract\n",
    "\n",
    "# Убедитесь, что tesseract установлен в системе и прописан в PATH\n",
    "# https://github.com/UB-Mannheim/tesseract/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b14b30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Указываем путь к фотографии документа\n",
    "image_path = 'task3/data/$2y$10$k1fd1.d6HmhGzjzlTay.ChRiDY8LgriFg.EupH6kUCTCt9fjRm.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e374470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "# Указываем перечень контрольных (уникальных) слов для определения типа.\n",
    "DOCUMENTS_TYPE = {\n",
    "    'договор': ['договор',],\n",
    "    'паспорт': ['отделом', 'мвд'],\n",
    "    'СТС': ['certificat'],\n",
    "    'ИНН': ['налогам'],\n",
    "    'права': ['водительское'],\n",
    "}\n",
    "\n",
    "\n",
    "# Само распознавание.\n",
    "def ocr(file_path):\n",
    "    \"\"\"Принимаем путь к картинке и возвращаем сырые данные.\"\"\"\n",
    "    image = cv2.imread(file_path)\n",
    "    # Конвертация изображения в градации серого.\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Конфиг для лучшего распознавания.\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    # Распознаем.\n",
    "    text = pytesseract.image_to_string(\n",
    "        gray_image,\n",
    "        lang='rus+eng',\n",
    "        config=custom_config\n",
    "    )\n",
    "    return set(text.lower().split())         # множество для скорости работы.\n",
    "\n",
    "\n",
    "def define_type(raw_text):\n",
    "    for key, values in DOCUMENTS_TYPE.items():\n",
    "        for value in values:\n",
    "            if value in raw_text:\n",
    "                return key\n",
    "    return 'Не удалось распознать документ.'\n",
    "\n",
    "\n",
    "def main():\n",
    "    raw_text = ocr(image_path)\n",
    "    result = define_type(raw_text)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d417d56",
   "metadata": {},
   "source": [
    "# Шестая задача"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1663fb6c",
   "metadata": {},
   "source": [
    "За основу берем решение 2 задачи. Добавляем веб-интерфейс, добавляем кеширование. Развертываем в контейнере Докер, выгружаем на докерхаб.\n",
    "  \n",
    "**Для развертывания контейнера выполните:**  \n",
    "*docker pull madzonedocker/car-color-detection:latest*  \n",
    "*docker run -p 7860:7860 --name car-color-container madzonedocker/car-color-detection:latest*  \n",
    "**Для проверки перейдите по ссылке:**  \n",
    "*http://localhost:7860*  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a615530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек\n",
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c07db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import lru_cache\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Загрузка модели YOLO\n",
    "model = YOLO('yolo11n-seg.pt')\n",
    "\n",
    "\n",
    "def detect_cars(model, image_rgb):\n",
    "    \"\"\"Выполняет детекцию автомобилей с помощью модели YOLO.\"\"\"\n",
    "    results = model(image_rgb)\n",
    "    cars = []\n",
    "    masks = []\n",
    "    for result in results:\n",
    "        for box, mask in zip(result.boxes, result.masks or []):\n",
    "            if int(box.cls) == 2:  # Класс 2 в COCO — автомобиль\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                cars.append((x1, y1, x2, y2))\n",
    "                mask_data = mask.data.cpu().numpy().squeeze()\n",
    "                masks.append(mask_data)\n",
    "    return cars, masks\n",
    "\n",
    "\n",
    "def process_car(image_rgb, car_coords, mask_data):\n",
    "    \"\"\"Обрабатывает один автомобиль: сегментирует, исключает стекла/колеса,\n",
    "    вычисляет цвет.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = car_coords\n",
    "    car_region = image_rgb[y1:y2, x1:x2].copy()\n",
    "\n",
    "    # Изменение размера маски до размеров bounding box\n",
    "    mask_resized = cv2.resize(mask_data, (x2 - x1, y2 - y1),\n",
    "                              interpolation=cv2.INTER_NEAREST)\n",
    "    mask_resized = (mask_resized > 0).astype(np.uint8) * 255\n",
    "\n",
    "    # Применение маски сегментации\n",
    "    car_segmented = cv2.bitwise_and(car_region, car_region, mask=mask_resized)\n",
    "\n",
    "    # Преобразование в HSV\n",
    "    car_hsv = cv2.cvtColor(car_segmented, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    # Маскирование стекол и колес\n",
    "    lower_glass = np.array([0, 0, 150])                 # Высокая яркость\n",
    "    upper_glass = np.array([180, 50, 255])              # Низкая насыщенность\n",
    "    lower_wheels = np.array([0, 0, 0])                  # Темные области\n",
    "    upper_wheels = np.array([180, 255, 50])             # Низкая яркость\n",
    "\n",
    "    mask_glass = cv2.inRange(car_hsv, lower_glass, upper_glass)\n",
    "    mask_wheels = cv2.inRange(car_hsv, lower_wheels, upper_wheels)\n",
    "    mask_exclude = cv2.bitwise_or(mask_glass, mask_wheels)\n",
    "    mask_body = cv2.bitwise_and(mask_resized, cv2.bitwise_not(mask_exclude))\n",
    "\n",
    "    # Применение финальной маски\n",
    "    car_body = cv2.bitwise_and(car_region, car_region, mask=mask_body)\n",
    "\n",
    "    # Вычисление среднего цвета\n",
    "    valid_pixels = car_body[mask_body > 0].reshape(-1, 3)\n",
    "    if len(valid_pixels) > 0:\n",
    "        mean_color = np.mean(valid_pixels, axis=0).astype(int)\n",
    "    else:\n",
    "        mean_color = np.array([128, 128, 128])\n",
    "\n",
    "    return tuple(mean_color)\n",
    "\n",
    "\n",
    "def visualize_results(image_rgb, cars, rgb_colors):\n",
    "    \"\"\"Визуализирует результаты: возвращает изображение.\"\"\"\n",
    "    vis_image = image_rgb.copy()\n",
    "\n",
    "    # Рисуем bounding box'ы и метки\n",
    "    for i, (x1, y1, x2, y2) in enumerate(cars):\n",
    "        cv2.rectangle(vis_image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        cv2.putText(vis_image, f'Car {i+1}', (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "    # Создаем фигуру\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Исходное изображение\n",
    "    plt.subplot(1, len(cars) + 1, 1)\n",
    "    plt.imshow(vis_image)\n",
    "    plt.title('Автомобили с определенными цветами')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Цветовые патчи\n",
    "    for i, color in enumerate(rgb_colors):\n",
    "        plt.subplot(1, len(cars) + 1, i + 2)\n",
    "        color_patch = np.ones((100, 100, 3)) * (np.array(color) / 255)\n",
    "        plt.imshow(color_patch)\n",
    "        plt.title(f'Авто {i+1}\\nRGB: {color}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Сохранение в буфер\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "    image = Image.open(buf)\n",
    "    return np.array(image)\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=100)\n",
    "def cached_process_image(image_bytes, shape):\n",
    "    \"\"\"Кэширует обработку изображения.\"\"\"\n",
    "    image_rgb = np.frombuffer(image_bytes, dtype=np.uint8).reshape(shape)\n",
    "    cars, masks = detect_cars(model, image_rgb)\n",
    "    if not cars:\n",
    "        return tuple(), tuple(), image_rgb\n",
    "\n",
    "    rgb_colors = []\n",
    "    for car_coords, mask_data in zip(cars, masks):\n",
    "        color = process_car(image_rgb, car_coords, mask_data)\n",
    "        rgb_colors.append(color)\n",
    "\n",
    "    vis_image = visualize_results(image_rgb, cars, rgb_colors)\n",
    "    return tuple(rgb_colors), tuple(cars), vis_image\n",
    "\n",
    "\n",
    "def demo_process_image(image):\n",
    "    \"\"\"Обрабатывает изображение для Gradio.\"\"\"\n",
    "    if image is None:\n",
    "        return 'Пожалуйста, загрузите изображение', None\n",
    "\n",
    "    try:\n",
    "        # Конвертация изображения в RGB\n",
    "        image_rgb = np.array(image)\n",
    "\n",
    "        # Подготовка данных для кэширования\n",
    "        image_bytes = image_rgb.tobytes()\n",
    "        shape = image_rgb.shape\n",
    "\n",
    "        # Обработка с кэшированием\n",
    "        rgb_colors, cars, vis_image = cached_process_image(image_bytes, shape)\n",
    "\n",
    "        if not cars:\n",
    "            return 'Автомобили не найдены', None\n",
    "\n",
    "        # Формирование текстового результата\n",
    "        result_text = '\\n'.join(\n",
    "            f'Авто {i+1}: RGB = {color}' for i, color in enumerate(rgb_colors)\n",
    "        )\n",
    "\n",
    "        return result_text, vis_image\n",
    "    except Exception as e:\n",
    "        return f'Ошибка обработки: {str(e)}', None\n",
    "\n",
    "\n",
    "# Создание интерфейса Gradio\n",
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown('# Определение цвета автомобилей')\n",
    "    gr.Markdown('Загрузите изображение, чтобы определить цвета автомобилей.')\n",
    "    with gr.Row():\n",
    "        input_image = gr.Image(type='pil',\n",
    "                               label='Загрузите фотографию автомобиля')\n",
    "    with gr.Row():\n",
    "        output_text = gr.Textbox(label='Цвета автомобилей (RGB)')\n",
    "        output_image = gr.Image(label='Результат обработки')\n",
    "    input_image.change(fn=demo_process_image,\n",
    "                       inputs=input_image,\n",
    "                       outputs=[output_text, output_image])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    interface.launch(server_name=\"0.0.0.0\", server_port=7860)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
